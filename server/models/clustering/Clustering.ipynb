{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.io import imread, imshow\n",
    "from skimage import filters\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas\n",
    "import multiprocessing\n",
    "from scipy.cluster.vq import vq,kmeans,whiten\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import load_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin \n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_root_name = \"AgeEstimator\"\n",
    "module_paths = [\n",
    "    os.path.abspath(os.path.join('..')),\n",
    "    os.path.abspath(os.path.join('../..')),\n",
    "    os.path.abspath(os.path.join('../../..'))\n",
    "]\n",
    "module_paths = list(filter(lambda x: x.endswith(module_root_name), module_paths))\n",
    "module_path = module_paths[0] if len(module_paths) == 1 else \"\"\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from server.data.dataset import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG16(include_top=True)\n",
    "\n",
    "def getPic(x_train):\n",
    "    vgg16_feature_list = []\n",
    "    for i in range(0, len(x_train)):\n",
    "        pic = image.load_img(x_train[i], target_size=(224, 224))\n",
    "        img_data = image.img_to_array(pic)\n",
    "        \n",
    "        img_data = np.expand_dims(img_data, axis=0)\n",
    "        img_data = preprocess_input(img_data)\n",
    "\n",
    "        vgg16_feature = model.predict(img_data)\n",
    "        vgg16_feature_np = np.array(vgg16_feature)\n",
    "        vgg16_feature_list.append(vgg16_feature_np.flatten())\n",
    "    vgg16_feature_list_np = np.array(vgg16_feature_list)\n",
    "    #data=whiten(train)\n",
    "    np.save(\"vgg16.npy\",vgg16_feature_list_np)\n",
    "    print(\"load image done\")\n",
    "    return vgg16_feature_list_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCAnalysis(vgg16_feature_list_np):    \n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=0.9)\n",
    "    pca_list = pca.fit_transform(vgg16_feature_list_np)\n",
    "    print(\"PCA done\")\n",
    "    return pca_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GNB_train(trainPoints, trainLabels):\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    gnb = GaussianNB().fit(trainPoints, trainLabels)\n",
    "    with open('gnb.pickle', 'wb') as f:\n",
    "        pickle.dump(gnb, f)\n",
    "    print(\"GNB done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVC_train(trainPoints, trainLabels):\n",
    "    from sklearn.svm import SVC\n",
    "    svclassifier = SVC(kernel='linear').fit(trainPoints, trainLabels)\n",
    "    with open('svc.pickle', 'wb') as f:\n",
    "        pickle.dump(svclassifier, f)\n",
    "    print('SVC done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_train(trainPoints, trainLabels):\n",
    "    k = 1000\n",
    "    knn = KNeighborsClassifier(n_neighbors=int(k), metric='euclidean').fit(trainPoints, trainLabels)\n",
    "    with open('knn.pickle', 'wb') as f:\n",
    "        pickle.dump(knn, f)\n",
    "    print(\"knn done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mbk_means_train(pca_list):\n",
    "    \n",
    "    mbk = MiniBatchKMeans(n_clusters=20, init='k-means++', max_iter=100, batch_size=100, verbose=0, compute_labels=True, random_state=None, \n",
    "                    tol=0.0, max_no_improvement=10, init_size=None, n_init=3, reassignment_ratio=0.01).fit(pca_list)\n",
    "    \n",
    "    mbk_means_cluster_centers = np.sort(mbk.cluster_centers_, axis = 0) \n",
    "    mbk_means_labels = pairwise_distances_argmin(pca_list, mbk_means_cluster_centers) \n",
    "    print(\"mbk-means done\")\n",
    "    \n",
    "    with open('mbk.pickle', 'wb') as f:\n",
    "        pickle.dump(mbk, f)\n",
    "    '''\n",
    "    with open('mbk_test.pickle', 'wb') as f:\n",
    "        pickle.dump(mbk, f)\n",
    "    '''\n",
    "    return mbk_means_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_mean_train(pca_list):\n",
    "    kmeans = KMeans(n_clusters=20).fit(pca_list)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    k_means_labels = pairwise_distances_argmin(pca_list, centroids) \n",
    "    print(\"k-means done\")\n",
    "   \n",
    "    with open('kmean.pickle', 'wb') as f:\n",
    "        pickle.dump(kmeans, f)\n",
    "    '''\n",
    "    with open('kmean_test.pickle', 'wb') as f:\n",
    "        pickle.dump(kmeans, f)\n",
    "    '''\n",
    "    return k_means_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(labels,model):\n",
    "    \n",
    "    fp = open(model+'_result.dat', 'w')\n",
    "    i = 0\n",
    "    for res in labels:\n",
    "        fp.write(str(res))\n",
    "        fp.write('\\t')\n",
    "        fp.write(str(y_train[i]))\n",
    "        i = i + 1\n",
    "        fp.write('\\n')\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149724\n",
      "GNB done\n",
      "knn done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    dl = DataLoader()\n",
    "    x_train, y_train = dl.load_train()\n",
    "    x_test, y_test = dl.load_test()\n",
    "    vgg16_feature_list_np = getPic(x_train)\n",
    "    \n",
    "    #vgg16_load = np.load(\"vgg16.npy\")\n",
    "    #print(len(vgg16_load))\n",
    "    \n",
    "    GNB_train(vgg16_feature_list_np,y_train)\n",
    "    #SVC_tran(vgg16_feature_list_np,y_train)\n",
    "    #knn_train(vgg16_load,y_train)\n",
    "    #pca_list = PCAnalysis(vgg16_load)\n",
    "    #mbk_means_labels = mbk_means_train(vgg16_feature_list_np)\n",
    "    #k_mean_labels = k_mean_train(vgg16_feature_list_np)\n",
    "    #write(mbk_means_labels,\"mbk\")\n",
    "    #write(k_mean_labels,\"kmean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149724\n"
     ]
    }
   ],
   "source": [
    "''' test\n",
    "dl = DataLoader()\n",
    "x_train, y_train = dl.load_train()\n",
    "x_test, y_test = dl.load_test()\n",
    "vgg16_load = np.load(\"vgg16.npy\")\n",
    "print(len(vgg16_load))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "loadImg = x_test[28]\n",
    "#loadImg = 'C:\\\\Users\\\\USER\\\\Pictures\\\\picture.jpg'\n",
    "pic = image.load_img(loadImg)\n",
    "pic = pic.resize((224,224))\n",
    "img_data = image.img_to_array(pic)\n",
    "vgg16_feature_list = []\n",
    "img_data = np.expand_dims(img_data, axis=0)\n",
    "img_data = preprocess_input(img_data)\n",
    "\n",
    "vgg16_feature = model.predict(img_data)\n",
    "vgg16_feature_np = np.array(vgg16_feature)\n",
    "test = vgg16_feature_np.flatten()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Project\\AgeEstimator\\server\\data\\dataset\\test\\10_utk_21626.jpg\n",
      "[26]\n",
      "[8]\n",
      "[26]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "with open('svc.pickle', 'rb') as f:\n",
    "    svc_load = pickle.load(f) \n",
    "    \n",
    "with open('gnb.pickle', 'rb') as f2:\n",
    "    gnb_load = pickle.load(f2) \n",
    "\n",
    "with open('knn.pickle', 'rb') as f3:\n",
    "    knn_load = pickle.load(f3) \n",
    "print(loadImg)\n",
    "print(svc_load.predict(vgg16_feature_np))\n",
    "print(gnb_load.predict(vgg16_feature_np))\n",
    "print(knn_load.predict(vgg16_feature_np))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
