{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Workaround to make packages work in both Jupyter notebook and Python\n",
    "MODULE_ROOT_NAME = \"AgeEstimator\"\n",
    "MODULE_PATHS = [\n",
    "    os.path.abspath(os.path.join('..')),\n",
    "    os.path.abspath(os.path.join('../..')),\n",
    "    os.path.abspath(os.path.join('../../..'))\n",
    "]\n",
    "MODULE_PATHS = list(\n",
    "    filter(lambda x: x.endswith(MODULE_ROOT_NAME), MODULE_PATHS))\n",
    "MODULE_PATH = MODULE_PATHS[0] if len(MODULE_PATHS) == 1 else \"\"\n",
    "if MODULE_PATH not in sys.path:\n",
    "    sys.path.append(MODULE_PATH)\n",
    "    \n",
    "from server.data.dataset import DataLoader\n",
    "from server.models.cnn.model import get_model, OLD_WEIGHTS_PATH, BEST_WEIGHTS_PATH, LABEL_MAPPING, get_models, N_CLASSES, IMAGE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.image as img\n",
    "import numpy as np\n",
    "import pandas\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_to_age_map():\n",
    "    return pandas.read_csv(\"./class_to_estimated_age.csv\", dtype=float).Age.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_to_category_map():\n",
    "    unique_labels = list(set(LABEL_MAPPING.values()))\n",
    "    category_map = {class_label: inx for inx, class_label in enumerate(unique_labels)}\n",
    "    category_map_r = {inx: class_label for inx, class_label in enumerate(unique_labels)}\n",
    "    return category_map, category_map_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_label(y):\n",
    "    category_map, _ = get_label_to_category_map()\n",
    "    normalize = lambda x:category_map[LABEL_MAPPING[x]]\n",
    "    labels = np.vectorize(normalize)(y)\n",
    "    return to_categorical(labels, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_generators():\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    \n",
    "    valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    return train_datagen, valid_datagen, test_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_generator(datagen, dataframe, directory, batch_size=batch_size):\n",
    "    g = datagen.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        directory=directory,\n",
    "        x_col=\"FilePath\",\n",
    "        y_col=\"Age\",\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=batch_size,\n",
    "#         class_mode='sparse',\n",
    "        class_mode=\"categorical\"\n",
    "    )\n",
    "\n",
    "    # Convert to tf.data to better utilize multiprocessing\n",
    "    n_class = len(np.unique(np.array(dataframe[\"Age\"])))\n",
    "    tf_g = tf.data.Dataset.from_generator(lambda: g,\n",
    "        output_types=(tf.float32, tf.float32),\n",
    "        output_shapes=(\n",
    "            tf.TensorShape([None, IMAGE_SIZE[0], IMAGE_SIZE[1], 3]), \n",
    "            tf.TensorShape([None, 55])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return tf_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_2_age = get_class_to_age_map()\n",
    "\n",
    "table = tf.lookup.StaticHashTable(\n",
    "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=list(class_2_age.keys()),\n",
    "        values=list(class_2_age.values()),\n",
    "        key_dtype=tf.int32, value_dtype=tf.float32\n",
    "    ),\n",
    "    default_value=tf.constant(-1.0),\n",
    "    name=\"class_weight\"\n",
    ")\n",
    "\n",
    "age_tensor = K.map_fn(lambda x: table.lookup(x),\n",
    "                      K.arange(len(class_2_age)),\n",
    "                      dtype=tf.float32)\n",
    "\n",
    "def mae_all_class(y_true, y_pred):\n",
    "    r\"\"\"Mean absolute error of the true class label and the average prediction.\"\"\"\n",
    "    if not tf.is_tensor(y_pred):\n",
    "        y_pred = K.constant(y_pred)\n",
    "        \n",
    "    # Calculate average prediction\n",
    "    age_pred = tf.tensordot(y_pred, age_tensor, axes=1)\n",
    "    \n",
    "    # Calculate true age\n",
    "    y_true = K.cast(y_true, y_pred.dtype)\n",
    "    y_true_idx = tf.math.argmax(y_true, axis=1, output_type=tf.int32)\n",
    "    age_true = table.lookup(y_true_idx)\n",
    "    return tf.math.reduce_mean(tf.math.abs(age_pred - age_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling and train/valid Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(x, y, name, sample_size=0):\n",
    "    # Stack to [[img, label], ...] matrix\n",
    "    stk = np.column_stack((x, y))\n",
    "    \n",
    "    # Save as csv\n",
    "    np.savetxt(\"%s.csv\" % (name), stk, fmt=\"%s\", delimiter=\",\", comments=\"\", header=\"FilePath,Age\")\n",
    "    \n",
    "    # `flow_from_dataframe` requires loading labels as string\n",
    "    df = pandas.read_csv(\"./%s.csv\" % (name), dtype=str)\n",
    "    \n",
    "    return df if sample_size == 0 else df.sample(n=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_valid(df):\n",
    "    train_df = df.sample(frac=0.9)\n",
    "    validation_df = df.drop(train_df.index)\n",
    "    return train_df, validation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(log_dir):\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "    # Don't waste our time/resource on bad training\n",
    "    es = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        verbose=1,\n",
    "        patience=100)\n",
    "    \n",
    "    tb = TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=0,\n",
    "        write_graph=True,\n",
    "        write_grads=False,\n",
    "        write_images=False,\n",
    "        embeddings_freq=0,\n",
    "        embeddings_layer_names=None,\n",
    "        embeddings_metadata=None,\n",
    "        embeddings_data=None,\n",
    "        update_freq='epoch')\n",
    "    \n",
    "    # Save the best weight seen so far\n",
    "    mc = ModelCheckpoint(\n",
    "        BEST_WEIGHTS_PATH,\n",
    "#         monitor='val_loss',\n",
    "#         mode='min',\n",
    "        monitor='val_categorical_accuracy',\n",
    "        mode='max',\n",
    "        verbose=1,\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True)\n",
    "    \n",
    "    # Modify the best score for retrains\n",
    "    mc.best = 0.14363\n",
    "    \n",
    "    # Try to get rid of local minimum\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=20,\n",
    "        min_lr=0.000001)\n",
    "    \n",
    "    return [mc, es, tb, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_dir():\n",
    "    log_i = 0\n",
    "    log_dir = \"logs/run_\"\n",
    "    \n",
    "    while os.path.exists(log_dir + str(log_i)):\n",
    "        log_i += 1\n",
    "\n",
    "    return log_dir + str(log_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(y_true, y_predict, top_n=5):\n",
    "    r\"\"\"Compare the last 10 result of top 5 prediction and its label.\"\"\"\n",
    "    y_hat = y_predict.argsort(axis=1)[:,-top_n:]\n",
    "    y_true = np.argmax(y_true, axis=1)\n",
    "    print(y_hat[-10:])\n",
    "    print(y_true[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a lot of models\n",
    "\n",
    "Train with a small portion of our dataset to compare the performace of the combinations of hyperparameters, so we can decide which model should be trained with a larger epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_many(train_generator, valid_generator, train_len, valid_len):\n",
    "    epochs = 20\n",
    "    models = get_models()\n",
    "    \n",
    "    for m in models:\n",
    "        model_name, optimizer, model = m\n",
    "        print(\"== Training %s ==\" % model_name)\n",
    "\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, \\\n",
    "                      metrics=[mae_all_class ,\"categorical_accuracy\"])\n",
    "\n",
    "        log_dir = get_log_dir()\n",
    "        callbacks = get_callbacks(log_dir + \"/%s\" % model_name)\n",
    "\n",
    "        model.fit(\n",
    "            x=train_generator,\n",
    "            steps_per_epoch=train_len // batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            validation_data=valid_generator,\n",
    "            validation_steps=valid_len // batch_size,\n",
    "            callbacks=callbacks,\n",
    "            workers=max(2, multiprocessing.cpu_count() - 2),\n",
    "            use_multiprocessing=True\n",
    "        )\n",
    "\n",
    "        model.save_weights(\"%s_weight.hdf5\" % model_name)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the finalized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y):\n",
    "    epochs = 1000\n",
    "    \n",
    "    optimizer = Nadam(lr=0.00007, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "    model = get_model()\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, \\\n",
    "        metrics=[mae_all_class, \"categorical_accuracy\"])\n",
    "    \n",
    "    if os.path.exists(BEST_WEIGHTS_PATH):\n",
    "        model.load_weights(BEST_WEIGHTS_PATH)\n",
    "        print(\"best weight [%s] loaded.\" % BEST_WEIGHTS_PATH)\n",
    "#     elif os.path.exists(OLD_WEIGHTS_PATH):\n",
    "#         model.load_weights(OLD_WEIGHTS_PATH)\n",
    "#         print(\"old weight [%s] loaded.\" % OLD_WEIGHTS_PATH)\n",
    "    else:\n",
    "        print(\"fresh start.\")\n",
    "            \n",
    "    log_dir = get_log_dir()\n",
    "    callbacks = get_callbacks(log_dir)\n",
    "\n",
    "    train_len = round(len(x) * 0.9)\n",
    "    \n",
    "    model.fit(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_split=0.1,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks,\n",
    "        workers=max(2, multiprocessing.cpu_count() - 2),\n",
    "        use_multiprocessing=True\n",
    "    )\n",
    "    \n",
    "    model.save_weights(OLD_WEIGHTS_PATH)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entry point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(sample_size=0, is_final_model=True):\n",
    "    dl = DataLoader()\n",
    "    use_bottleneck_features = True\n",
    "    x_train, y_train = dl.load_train(use_bottleneck_features)\n",
    "    x_test, y_test = dl.load_test(use_bottleneck_features)\n",
    "    \n",
    "    # Discretizate the continuous age into ordinal labels and map it with one-hot encoding\n",
    "    y_train = normalize_label(y_train)\n",
    "    y_test = normalize_label(y_test)\n",
    "    \n",
    "#     # The size is too large, so build a csv file for (image_filename/label) mapping\n",
    "#     train_df = get_dataframe(x_train, y_train, \"train\", sample_size=sample_size)\n",
    "#     train_df, valid_df = split_train_valid(train_df)\n",
    "#     test_df = get_dataframe(x_test, y_test, \"test\", sample_size=sample_size // 10)\n",
    "\n",
    "#     # Data augmentation for training set\n",
    "#     train_datagen, valid_datagen, test_datagen = get_img_generators()\n",
    "#     train_generator = to_generator(train_datagen, train_df, dl.train_dir)\n",
    "#     valid_generator = to_generator(valid_datagen, valid_df, dl.train_dir)\n",
    "#     test_generator = to_generator(test_datagen, test_df, dl.test_dir)\n",
    "    \n",
    "#     train_len = len(x_train)\n",
    "#     valid_len = len(valid_df)\n",
    "    test_len = len(x_test)\n",
    "    \n",
    "    if is_final_model:\n",
    "        # If it's a finalized model, train with a larger epochs\n",
    "        trained_model = train(x_train, y_train)\n",
    "\n",
    "        evaluation = trained_model.evaluate(\n",
    "            x=x_test, y=y_test)\n",
    "        y_hat = trained_model.predict(\n",
    "            x=x_test)\n",
    "        \n",
    "        print(evaluation)\n",
    "        compare_results(y_test, y_hat)\n",
    "\n",
    "        return evaluation, y_hat, y_test\n",
    "    \n",
    "#     else:\n",
    "#         train_many(train_generator, valid_generator, train_len, valid_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 2048)]            0         \n",
      "_________________________________________________________________\n",
      "d0 (Dense)                   (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "d1 (Dense)                   (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "d2 (Dense)                   (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dr1 (Dropout)                (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "d3 (Dense)                   (None, 55)                14135     \n",
      "=================================================================\n",
      "Total params: 2,775,607\n",
      "Trainable params: 2,772,023\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "best weight [best_nn_classification_weights.hdf5] loaded.\n",
      "Train on 134466 samples, validate on 14941 samples\n",
      "Epoch 1/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.3297 - mae_all_class: 1.4383 - categorical_accuracy: 0.5293\n",
      "Epoch 00001: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 16s 121us/sample - loss: 1.3299 - mae_all_class: 1.4402 - categorical_accuracy: 0.5293 - val_loss: 4.5850 - val_mae_all_class: 4.3072 - val_categorical_accuracy: 0.1411\n",
      "Epoch 2/1000\n",
      "134080/134466 [============================>.] - ETA: 0s - loss: 1.3271 - mae_all_class: 1.4459 - categorical_accuracy: 0.5292\n",
      "Epoch 00002: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 106us/sample - loss: 1.3274 - mae_all_class: 1.4562 - categorical_accuracy: 0.5292 - val_loss: 4.5977 - val_mae_all_class: 4.3103 - val_categorical_accuracy: 0.1423\n",
      "Epoch 3/1000\n",
      "134016/134466 [============================>.] - ETA: 0s - loss: 1.3198 - mae_all_class: 1.4310 - categorical_accuracy: 0.5315\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 106us/sample - loss: 1.3197 - mae_all_class: 1.4402 - categorical_accuracy: 0.5316 - val_loss: 4.6035 - val_mae_all_class: 4.3248 - val_categorical_accuracy: 0.1416\n",
      "Epoch 4/1000\n",
      "134208/134466 [============================>.] - ETA: 0s - loss: 1.3220 - mae_all_class: 1.4493 - categorical_accuracy: 0.5316\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 106us/sample - loss: 1.3220 - mae_all_class: 1.4509 - categorical_accuracy: 0.5317 - val_loss: 4.6056 - val_mae_all_class: 4.3243 - val_categorical_accuracy: 0.1422\n",
      "Epoch 5/1000\n",
      "134464/134466 [============================>.] - ETA: 0s - loss: 1.3201 - mae_all_class: 1.4408 - categorical_accuracy: 0.5328\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 15s 108us/sample - loss: 1.3201 - mae_all_class: 1.4431 - categorical_accuracy: 0.5328 - val_loss: 4.6290 - val_mae_all_class: 4.3219 - val_categorical_accuracy: 0.1410\n",
      "Epoch 6/1000\n",
      "134400/134466 [============================>.] - ETA: 0s - loss: 1.3240 - mae_all_class: 1.4400 - categorical_accuracy: 0.5323\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 15s 112us/sample - loss: 1.3241 - mae_all_class: 1.4418 - categorical_accuracy: 0.5323 - val_loss: 4.6128 - val_mae_all_class: 4.3172 - val_categorical_accuracy: 0.1412\n",
      "Epoch 7/1000\n",
      "134080/134466 [============================>.] - ETA: 0s - loss: 1.3122 - mae_all_class: 1.4321 - categorical_accuracy: 0.5333\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.3120 - mae_all_class: 1.4362 - categorical_accuracy: 0.5334 - val_loss: 4.6366 - val_mae_all_class: 4.3274 - val_categorical_accuracy: 0.1406\n",
      "Epoch 8/1000\n",
      "134464/134466 [============================>.] - ETA: 0s - loss: 1.3151 - mae_all_class: 1.4303 - categorical_accuracy: 0.5337\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 106us/sample - loss: 1.3152 - mae_all_class: 1.4370 - categorical_accuracy: 0.5337 - val_loss: 4.6420 - val_mae_all_class: 4.3252 - val_categorical_accuracy: 0.1425\n",
      "Epoch 9/1000\n",
      "134016/134466 [============================>.] - ETA: 0s - loss: 1.3177 - mae_all_class: 1.4316 - categorical_accuracy: 0.5337\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 106us/sample - loss: 1.3181 - mae_all_class: 1.4339 - categorical_accuracy: 0.5336 - val_loss: 4.6323 - val_mae_all_class: 4.3200 - val_categorical_accuracy: 0.1423\n",
      "Epoch 10/1000\n",
      "134080/134466 [============================>.] - ETA: 0s - loss: 1.3120 - mae_all_class: 1.4282 - categorical_accuracy: 0.5339\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.3118 - mae_all_class: 1.4281 - categorical_accuracy: 0.5340 - val_loss: 4.6400 - val_mae_all_class: 4.3245 - val_categorical_accuracy: 0.1428\n",
      "Epoch 11/1000\n",
      "134016/134466 [============================>.] - ETA: 0s - loss: 1.3097 - mae_all_class: 1.4287 - categorical_accuracy: 0.5370\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 15s 109us/sample - loss: 1.3098 - mae_all_class: 1.4296 - categorical_accuracy: 0.5369 - val_loss: 4.6463 - val_mae_all_class: 4.3276 - val_categorical_accuracy: 0.1416\n",
      "Epoch 12/1000\n",
      "134400/134466 [============================>.] - ETA: 0s - loss: 1.3077 - mae_all_class: 1.4240 - categorical_accuracy: 0.5372\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 108us/sample - loss: 1.3077 - mae_all_class: 1.4248 - categorical_accuracy: 0.5372 - val_loss: 4.6691 - val_mae_all_class: 4.3220 - val_categorical_accuracy: 0.1416\n",
      "Epoch 13/1000\n",
      "134080/134466 [============================>.] - ETA: 0s - loss: 1.3111 - mae_all_class: 1.4274 - categorical_accuracy: 0.5354\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.3114 - mae_all_class: 1.4284 - categorical_accuracy: 0.5352 - val_loss: 4.6584 - val_mae_all_class: 4.3315 - val_categorical_accuracy: 0.1420\n",
      "Epoch 14/1000\n",
      "134208/134466 [============================>.] - ETA: 0s - loss: 1.3081 - mae_all_class: 1.4272 - categorical_accuracy: 0.5370\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.3082 - mae_all_class: 1.4316 - categorical_accuracy: 0.5371 - val_loss: 4.6579 - val_mae_all_class: 4.3305 - val_categorical_accuracy: 0.1422\n",
      "Epoch 15/1000\n",
      "134464/134466 [============================>.] - ETA: 0s - loss: 1.3031 - mae_all_class: 1.4279 - categorical_accuracy: 0.5390\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.3031 - mae_all_class: 1.4327 - categorical_accuracy: 0.5390 - val_loss: 4.6644 - val_mae_all_class: 4.3283 - val_categorical_accuracy: 0.1404\n",
      "Epoch 16/1000\n",
      "134208/134466 [============================>.] - ETA: 0s - loss: 1.3043 - mae_all_class: 1.4245 - categorical_accuracy: 0.5383\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.3047 - mae_all_class: 1.4272 - categorical_accuracy: 0.5382 - val_loss: 4.6777 - val_mae_all_class: 4.3318 - val_categorical_accuracy: 0.1413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000\n",
      "134080/134466 [============================>.] - ETA: 0s - loss: 1.2999 - mae_all_class: 1.4213 - categorical_accuracy: 0.5386\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.3001 - mae_all_class: 1.4263 - categorical_accuracy: 0.5385 - val_loss: 4.6844 - val_mae_all_class: 4.3271 - val_categorical_accuracy: 0.1413\n",
      "Epoch 18/1000\n",
      "134016/134466 [============================>.] - ETA: 0s - loss: 1.2975 - mae_all_class: 1.4069 - categorical_accuracy: 0.5398\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2974 - mae_all_class: 1.4066 - categorical_accuracy: 0.5399 - val_loss: 4.6819 - val_mae_all_class: 4.3357 - val_categorical_accuracy: 0.1410\n",
      "Epoch 19/1000\n",
      "134016/134466 [============================>.] - ETA: 0s - loss: 1.2999 - mae_all_class: 1.4231 - categorical_accuracy: 0.5413\n",
      "Epoch 00019: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.3000 - mae_all_class: 1.4236 - categorical_accuracy: 0.5413 - val_loss: 4.6736 - val_mae_all_class: 4.3317 - val_categorical_accuracy: 0.1412\n",
      "Epoch 20/1000\n",
      "134208/134466 [============================>.] - ETA: 0s - loss: 1.2955 - mae_all_class: 1.4218 - categorical_accuracy: 0.5398\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2955 - mae_all_class: 1.4291 - categorical_accuracy: 0.5398 - val_loss: 4.7018 - val_mae_all_class: 4.3336 - val_categorical_accuracy: 0.1420\n",
      "Epoch 21/1000\n",
      "134464/134466 [============================>.] - ETA: 0s - loss: 1.2995 - mae_all_class: 1.4205 - categorical_accuracy: 0.5402\n",
      "Epoch 00021: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2996 - mae_all_class: 1.4237 - categorical_accuracy: 0.5402 - val_loss: 4.6994 - val_mae_all_class: 4.3294 - val_categorical_accuracy: 0.1420\n",
      "Epoch 22/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2863 - mae_all_class: 1.4070 - categorical_accuracy: 0.5422\n",
      "Epoch 00022: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2861 - mae_all_class: 1.4062 - categorical_accuracy: 0.5422 - val_loss: 4.6901 - val_mae_all_class: 4.3312 - val_categorical_accuracy: 0.1414\n",
      "Epoch 23/1000\n",
      "134016/134466 [============================>.] - ETA: 0s - loss: 1.2872 - mae_all_class: 1.4133 - categorical_accuracy: 0.5415\n",
      "Epoch 00023: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2871 - mae_all_class: 1.4144 - categorical_accuracy: 0.5417 - val_loss: 4.7053 - val_mae_all_class: 4.3293 - val_categorical_accuracy: 0.1409\n",
      "Epoch 24/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2865 - mae_all_class: 1.4073 - categorical_accuracy: 0.5423\n",
      "Epoch 00024: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2862 - mae_all_class: 1.4073 - categorical_accuracy: 0.5422 - val_loss: 4.6957 - val_mae_all_class: 4.3329 - val_categorical_accuracy: 0.1412\n",
      "Epoch 25/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2863 - mae_all_class: 1.4035 - categorical_accuracy: 0.5435\n",
      "Epoch 00025: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2865 - mae_all_class: 1.4083 - categorical_accuracy: 0.5435 - val_loss: 4.7097 - val_mae_all_class: 4.3345 - val_categorical_accuracy: 0.1417\n",
      "Epoch 26/1000\n",
      "134272/134466 [============================>.] - ETA: 0s - loss: 1.2840 - mae_all_class: 1.3959 - categorical_accuracy: 0.5458\n",
      "Epoch 00026: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 104us/sample - loss: 1.2841 - mae_all_class: 1.3965 - categorical_accuracy: 0.5458 - val_loss: 4.7176 - val_mae_all_class: 4.3306 - val_categorical_accuracy: 0.1413\n",
      "Epoch 27/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2823 - mae_all_class: 1.4110 - categorical_accuracy: 0.5446\n",
      "Epoch 00027: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2826 - mae_all_class: 1.4169 - categorical_accuracy: 0.5445 - val_loss: 4.7237 - val_mae_all_class: 4.3378 - val_categorical_accuracy: 0.1414\n",
      "Epoch 28/1000\n",
      "134208/134466 [============================>.] - ETA: 0s - loss: 1.2826 - mae_all_class: 1.4050 - categorical_accuracy: 0.5450\n",
      "Epoch 00028: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2825 - mae_all_class: 1.4075 - categorical_accuracy: 0.5451 - val_loss: 4.7173 - val_mae_all_class: 4.3334 - val_categorical_accuracy: 0.1422\n",
      "Epoch 29/1000\n",
      "134272/134466 [============================>.] - ETA: 0s - loss: 1.2796 - mae_all_class: 1.3995 - categorical_accuracy: 0.5464\n",
      "Epoch 00029: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2796 - mae_all_class: 1.4006 - categorical_accuracy: 0.5464 - val_loss: 4.7149 - val_mae_all_class: 4.3407 - val_categorical_accuracy: 0.1418\n",
      "Epoch 30/1000\n",
      "134272/134466 [============================>.] - ETA: 0s - loss: 1.2835 - mae_all_class: 1.4048 - categorical_accuracy: 0.5446\n",
      "Epoch 00030: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2834 - mae_all_class: 1.4056 - categorical_accuracy: 0.5446 - val_loss: 4.7220 - val_mae_all_class: 4.3428 - val_categorical_accuracy: 0.1424\n",
      "Epoch 31/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2801 - mae_all_class: 1.3955 - categorical_accuracy: 0.5447\n",
      "Epoch 00031: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2801 - mae_all_class: 1.3965 - categorical_accuracy: 0.5446 - val_loss: 4.7315 - val_mae_all_class: 4.3402 - val_categorical_accuracy: 0.1423\n",
      "Epoch 32/1000\n",
      "134336/134466 [============================>.] - ETA: 0s - loss: 1.2838 - mae_all_class: 1.4095 - categorical_accuracy: 0.5457\n",
      "Epoch 00032: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 108us/sample - loss: 1.2840 - mae_all_class: 1.4114 - categorical_accuracy: 0.5457 - val_loss: 4.7247 - val_mae_all_class: 4.3408 - val_categorical_accuracy: 0.1404\n",
      "Epoch 33/1000\n",
      "134272/134466 [============================>.] - ETA: 0s - loss: 1.2796 - mae_all_class: 1.4017 - categorical_accuracy: 0.5461\n",
      "Epoch 00033: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2797 - mae_all_class: 1.4021 - categorical_accuracy: 0.5461 - val_loss: 4.7292 - val_mae_all_class: 4.3418 - val_categorical_accuracy: 0.1426\n",
      "Epoch 34/1000\n",
      "134208/134466 [============================>.] - ETA: 0s - loss: 1.2807 - mae_all_class: 1.3955 - categorical_accuracy: 0.5453\n",
      "Epoch 00034: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2806 - mae_all_class: 1.3953 - categorical_accuracy: 0.5453 - val_loss: 4.7287 - val_mae_all_class: 4.3343 - val_categorical_accuracy: 0.1408\n",
      "Epoch 35/1000\n",
      "134400/134466 [============================>.] - ETA: 0s - loss: 1.2788 - mae_all_class: 1.3951 - categorical_accuracy: 0.5447\n",
      "Epoch 00035: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2790 - mae_all_class: 1.3986 - categorical_accuracy: 0.5447 - val_loss: 4.7262 - val_mae_all_class: 4.3427 - val_categorical_accuracy: 0.1409\n",
      "Epoch 36/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134016/134466 [============================>.] - ETA: 0s - loss: 1.2779 - mae_all_class: 1.3939 - categorical_accuracy: 0.5466\n",
      "Epoch 00036: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2781 - mae_all_class: 1.4025 - categorical_accuracy: 0.5466 - val_loss: 4.7449 - val_mae_all_class: 4.3408 - val_categorical_accuracy: 0.1412\n",
      "Epoch 37/1000\n",
      "134208/134466 [============================>.] - ETA: 0s - loss: 1.2774 - mae_all_class: 1.4033 - categorical_accuracy: 0.5471\n",
      "Epoch 00037: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2777 - mae_all_class: 1.4074 - categorical_accuracy: 0.5471 - val_loss: 4.7323 - val_mae_all_class: 4.3413 - val_categorical_accuracy: 0.1417\n",
      "Epoch 38/1000\n",
      "134016/134466 [============================>.] - ETA: 0s - loss: 1.2772 - mae_all_class: 1.3937 - categorical_accuracy: 0.5457\n",
      "Epoch 00038: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 106us/sample - loss: 1.2769 - mae_all_class: 1.3949 - categorical_accuracy: 0.5457 - val_loss: 4.7405 - val_mae_all_class: 4.3361 - val_categorical_accuracy: 0.1413\n",
      "Epoch 39/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2790 - mae_all_class: 1.4005 - categorical_accuracy: 0.5454\n",
      "Epoch 00039: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2791 - mae_all_class: 1.4048 - categorical_accuracy: 0.5453 - val_loss: 4.7306 - val_mae_all_class: 4.3326 - val_categorical_accuracy: 0.1408\n",
      "Epoch 40/1000\n",
      "134080/134466 [============================>.] - ETA: 0s - loss: 1.2782 - mae_all_class: 1.3994 - categorical_accuracy: 0.5468\n",
      "Epoch 00040: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 15s 108us/sample - loss: 1.2782 - mae_all_class: 1.4054 - categorical_accuracy: 0.5469 - val_loss: 4.7333 - val_mae_all_class: 4.3322 - val_categorical_accuracy: 0.1410\n",
      "Epoch 41/1000\n",
      "134080/134466 [============================>.] - ETA: 0s - loss: 1.2752 - mae_all_class: 1.3885 - categorical_accuracy: 0.5464\n",
      "Epoch 00041: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 108us/sample - loss: 1.2753 - mae_all_class: 1.3902 - categorical_accuracy: 0.5464 - val_loss: 4.7449 - val_mae_all_class: 4.3339 - val_categorical_accuracy: 0.1426\n",
      "Epoch 42/1000\n",
      "134464/134466 [============================>.] - ETA: 0s - loss: 1.2744 - mae_all_class: 1.3895 - categorical_accuracy: 0.5474\n",
      "Epoch 00042: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2745 - mae_all_class: 1.3922 - categorical_accuracy: 0.5474 - val_loss: 4.7461 - val_mae_all_class: 4.3345 - val_categorical_accuracy: 0.1424\n",
      "Epoch 43/1000\n",
      "134016/134466 [============================>.] - ETA: 0s - loss: 1.2766 - mae_all_class: 1.3984 - categorical_accuracy: 0.5473\n",
      "Epoch 00043: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2768 - mae_all_class: 1.4028 - categorical_accuracy: 0.5473 - val_loss: 4.7571 - val_mae_all_class: 4.3309 - val_categorical_accuracy: 0.1412\n",
      "Epoch 44/1000\n",
      "134080/134466 [============================>.] - ETA: 0s - loss: 1.2762 - mae_all_class: 1.3982 - categorical_accuracy: 0.5472\n",
      "Epoch 00044: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2764 - mae_all_class: 1.3986 - categorical_accuracy: 0.5472 - val_loss: 4.7428 - val_mae_all_class: 4.3406 - val_categorical_accuracy: 0.1417\n",
      "Epoch 45/1000\n",
      "134272/134466 [============================>.] - ETA: 0s - loss: 1.2744 - mae_all_class: 1.3891 - categorical_accuracy: 0.5461\n",
      "Epoch 00045: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2744 - mae_all_class: 1.3895 - categorical_accuracy: 0.5461 - val_loss: 4.7523 - val_mae_all_class: 4.3308 - val_categorical_accuracy: 0.1418\n",
      "Epoch 46/1000\n",
      "134016/134466 [============================>.] - ETA: 0s - loss: 1.2767 - mae_all_class: 1.3881 - categorical_accuracy: 0.5466\n",
      "Epoch 00046: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2768 - mae_all_class: 1.3937 - categorical_accuracy: 0.5466 - val_loss: 4.7414 - val_mae_all_class: 4.3408 - val_categorical_accuracy: 0.1413\n",
      "Epoch 47/1000\n",
      "134208/134466 [============================>.] - ETA: 0s - loss: 1.2774 - mae_all_class: 1.3927 - categorical_accuracy: 0.5469\n",
      "Epoch 00047: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2777 - mae_all_class: 1.3945 - categorical_accuracy: 0.5469 - val_loss: 4.7476 - val_mae_all_class: 4.3369 - val_categorical_accuracy: 0.1410\n",
      "Epoch 48/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2725 - mae_all_class: 1.3891 - categorical_accuracy: 0.5475\n",
      "Epoch 00048: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2725 - mae_all_class: 1.3927 - categorical_accuracy: 0.5475 - val_loss: 4.7405 - val_mae_all_class: 4.3369 - val_categorical_accuracy: 0.1412\n",
      "Epoch 49/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2741 - mae_all_class: 1.3891 - categorical_accuracy: 0.5469\n",
      "Epoch 00049: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2744 - mae_all_class: 1.3947 - categorical_accuracy: 0.5468 - val_loss: 4.7475 - val_mae_all_class: 4.3394 - val_categorical_accuracy: 0.1410\n",
      "Epoch 50/1000\n",
      "134208/134466 [============================>.] - ETA: 0s - loss: 1.2730 - mae_all_class: 1.3860 - categorical_accuracy: 0.5475\n",
      "Epoch 00050: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2731 - mae_all_class: 1.3897 - categorical_accuracy: 0.5475 - val_loss: 4.7478 - val_mae_all_class: 4.3419 - val_categorical_accuracy: 0.1419\n",
      "Epoch 51/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2748 - mae_all_class: 1.3896 - categorical_accuracy: 0.5464\n",
      "Epoch 00051: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2748 - mae_all_class: 1.3925 - categorical_accuracy: 0.5464 - val_loss: 4.7413 - val_mae_all_class: 4.3401 - val_categorical_accuracy: 0.1415\n",
      "Epoch 52/1000\n",
      "134016/134466 [============================>.] - ETA: 0s - loss: 1.2736 - mae_all_class: 1.3891 - categorical_accuracy: 0.5468\n",
      "Epoch 00052: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2741 - mae_all_class: 1.3908 - categorical_accuracy: 0.5467 - val_loss: 4.7428 - val_mae_all_class: 4.3397 - val_categorical_accuracy: 0.1418\n",
      "Epoch 53/1000\n",
      "134464/134466 [============================>.] - ETA: 0s - loss: 1.2748 - mae_all_class: 1.3837 - categorical_accuracy: 0.5470\n",
      "Epoch 00053: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 15s 108us/sample - loss: 1.2750 - mae_all_class: 1.3892 - categorical_accuracy: 0.5470 - val_loss: 4.7536 - val_mae_all_class: 4.3439 - val_categorical_accuracy: 0.1416\n",
      "Epoch 54/1000\n",
      "134400/134466 [============================>.] - ETA: 0s - loss: 1.2755 - mae_all_class: 1.3924 - categorical_accuracy: 0.5471\n",
      "Epoch 00054: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2756 - mae_all_class: 1.3954 - categorical_accuracy: 0.5471 - val_loss: 4.7520 - val_mae_all_class: 4.3411 - val_categorical_accuracy: 0.1419\n",
      "Epoch 55/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134208/134466 [============================>.] - ETA: 0s - loss: 1.2754 - mae_all_class: 1.3961 - categorical_accuracy: 0.5459\n",
      "Epoch 00055: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2755 - mae_all_class: 1.3985 - categorical_accuracy: 0.5458 - val_loss: 4.7446 - val_mae_all_class: 4.3358 - val_categorical_accuracy: 0.1420\n",
      "Epoch 56/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2703 - mae_all_class: 1.3836 - categorical_accuracy: 0.5487\n",
      "Epoch 00056: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2706 - mae_all_class: 1.3847 - categorical_accuracy: 0.5486 - val_loss: 4.7437 - val_mae_all_class: 4.3432 - val_categorical_accuracy: 0.1410\n",
      "Epoch 57/1000\n",
      "134208/134466 [============================>.] - ETA: 0s - loss: 1.2737 - mae_all_class: 1.3910 - categorical_accuracy: 0.5481\n",
      "Epoch 00057: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2737 - mae_all_class: 1.3992 - categorical_accuracy: 0.5482 - val_loss: 4.7422 - val_mae_all_class: 4.3374 - val_categorical_accuracy: 0.1414\n",
      "Epoch 58/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2766 - mae_all_class: 1.3870 - categorical_accuracy: 0.5473\n",
      "Epoch 00058: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2768 - mae_all_class: 1.3921 - categorical_accuracy: 0.5473 - val_loss: 4.7426 - val_mae_all_class: 4.3391 - val_categorical_accuracy: 0.1418\n",
      "Epoch 59/1000\n",
      "134208/134466 [============================>.] - ETA: 0s - loss: 1.2747 - mae_all_class: 1.3928 - categorical_accuracy: 0.5458\n",
      "Epoch 00059: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2747 - mae_all_class: 1.3945 - categorical_accuracy: 0.5458 - val_loss: 4.7446 - val_mae_all_class: 4.3420 - val_categorical_accuracy: 0.1418\n",
      "Epoch 60/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2761 - mae_all_class: 1.3950 - categorical_accuracy: 0.5471\n",
      "Epoch 00060: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2762 - mae_all_class: 1.4011 - categorical_accuracy: 0.5471 - val_loss: 4.7402 - val_mae_all_class: 4.3376 - val_categorical_accuracy: 0.1424\n",
      "Epoch 61/1000\n",
      "134336/134466 [============================>.] - ETA: 0s - loss: 1.2741 - mae_all_class: 1.3836 - categorical_accuracy: 0.5483\n",
      "Epoch 00061: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2743 - mae_all_class: 1.3952 - categorical_accuracy: 0.5482 - val_loss: 4.7579 - val_mae_all_class: 4.3384 - val_categorical_accuracy: 0.1412\n",
      "Epoch 62/1000\n",
      "134464/134466 [============================>.] - ETA: 0s - loss: 1.2759 - mae_all_class: 1.3990 - categorical_accuracy: 0.5487\n",
      "Epoch 00062: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2759 - mae_all_class: 1.4008 - categorical_accuracy: 0.5487 - val_loss: 4.7531 - val_mae_all_class: 4.3389 - val_categorical_accuracy: 0.1415\n",
      "Epoch 63/1000\n",
      "134016/134466 [============================>.] - ETA: 0s - loss: 1.2698 - mae_all_class: 1.3832 - categorical_accuracy: 0.5495\n",
      "Epoch 00063: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2703 - mae_all_class: 1.3876 - categorical_accuracy: 0.5494 - val_loss: 4.7581 - val_mae_all_class: 4.3382 - val_categorical_accuracy: 0.1414\n",
      "Epoch 64/1000\n",
      "134016/134466 [============================>.] - ETA: 0s - loss: 1.2719 - mae_all_class: 1.3889 - categorical_accuracy: 0.5477\n",
      "Epoch 00064: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2719 - mae_all_class: 1.3889 - categorical_accuracy: 0.5477 - val_loss: 4.7571 - val_mae_all_class: 4.3358 - val_categorical_accuracy: 0.1406\n",
      "Epoch 65/1000\n",
      "134400/134466 [============================>.] - ETA: 0s - loss: 1.2729 - mae_all_class: 1.3855 - categorical_accuracy: 0.5495\n",
      "Epoch 00065: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2730 - mae_all_class: 1.3855 - categorical_accuracy: 0.5496 - val_loss: 4.7468 - val_mae_all_class: 4.3401 - val_categorical_accuracy: 0.1420\n",
      "Epoch 66/1000\n",
      "134080/134466 [============================>.] - ETA: 0s - loss: 1.2747 - mae_all_class: 1.3827 - categorical_accuracy: 0.5474\n",
      "Epoch 00066: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2747 - mae_all_class: 1.3877 - categorical_accuracy: 0.5474 - val_loss: 4.7478 - val_mae_all_class: 4.3417 - val_categorical_accuracy: 0.1403\n",
      "Epoch 67/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2721 - mae_all_class: 1.3943 - categorical_accuracy: 0.5495\n",
      "Epoch 00067: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2721 - mae_all_class: 1.4014 - categorical_accuracy: 0.5494 - val_loss: 4.7415 - val_mae_all_class: 4.3392 - val_categorical_accuracy: 0.1406\n",
      "Epoch 68/1000\n",
      "134208/134466 [============================>.] - ETA: 0s - loss: 1.2742 - mae_all_class: 1.3949 - categorical_accuracy: 0.5492\n",
      "Epoch 00068: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2743 - mae_all_class: 1.3967 - categorical_accuracy: 0.5492 - val_loss: 4.7579 - val_mae_all_class: 4.3400 - val_categorical_accuracy: 0.1398\n",
      "Epoch 69/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2769 - mae_all_class: 1.3946 - categorical_accuracy: 0.5472\n",
      "Epoch 00069: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2767 - mae_all_class: 1.3986 - categorical_accuracy: 0.5473 - val_loss: 4.7580 - val_mae_all_class: 4.3369 - val_categorical_accuracy: 0.1410\n",
      "Epoch 70/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2711 - mae_all_class: 1.3878 - categorical_accuracy: 0.5497\n",
      "Epoch 00070: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2712 - mae_all_class: 1.3943 - categorical_accuracy: 0.5496 - val_loss: 4.7452 - val_mae_all_class: 4.3391 - val_categorical_accuracy: 0.1408\n",
      "Epoch 71/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2746 - mae_all_class: 1.3843 - categorical_accuracy: 0.5464\n",
      "Epoch 00071: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2747 - mae_all_class: 1.3876 - categorical_accuracy: 0.5465 - val_loss: 4.7407 - val_mae_all_class: 4.3473 - val_categorical_accuracy: 0.1411\n",
      "Epoch 72/1000\n",
      "134080/134466 [============================>.] - ETA: 0s - loss: 1.2726 - mae_all_class: 1.3964 - categorical_accuracy: 0.5480\n",
      "Epoch 00072: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2726 - mae_all_class: 1.4006 - categorical_accuracy: 0.5479 - val_loss: 4.7481 - val_mae_all_class: 4.3373 - val_categorical_accuracy: 0.1426\n",
      "Epoch 73/1000\n",
      "134208/134466 [============================>.] - ETA: 0s - loss: 1.2757 - mae_all_class: 1.3983 - categorical_accuracy: 0.5477\n",
      "Epoch 00073: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2758 - mae_all_class: 1.4020 - categorical_accuracy: 0.5478 - val_loss: 4.7588 - val_mae_all_class: 4.3414 - val_categorical_accuracy: 0.1415\n",
      "Epoch 74/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134336/134466 [============================>.] - ETA: 0s - loss: 1.2750 - mae_all_class: 1.3909 - categorical_accuracy: 0.5471\n",
      "Epoch 00074: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 106us/sample - loss: 1.2750 - mae_all_class: 1.3917 - categorical_accuracy: 0.5471 - val_loss: 4.7522 - val_mae_all_class: 4.3480 - val_categorical_accuracy: 0.1414\n",
      "Epoch 75/1000\n",
      "134272/134466 [============================>.] - ETA: 0s - loss: 1.2735 - mae_all_class: 1.3943 - categorical_accuracy: 0.5471\n",
      "Epoch 00075: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2738 - mae_all_class: 1.3989 - categorical_accuracy: 0.5471 - val_loss: 4.7610 - val_mae_all_class: 4.3341 - val_categorical_accuracy: 0.1417\n",
      "Epoch 76/1000\n",
      "134016/134466 [============================>.] - ETA: 0s - loss: 1.2752 - mae_all_class: 1.3933 - categorical_accuracy: 0.5476\n",
      "Epoch 00076: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2754 - mae_all_class: 1.3967 - categorical_accuracy: 0.5475 - val_loss: 4.7513 - val_mae_all_class: 4.3377 - val_categorical_accuracy: 0.1418\n",
      "Epoch 77/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2736 - mae_all_class: 1.3902 - categorical_accuracy: 0.5467\n",
      "Epoch 00077: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2733 - mae_all_class: 1.3907 - categorical_accuracy: 0.5468 - val_loss: 4.7481 - val_mae_all_class: 4.3372 - val_categorical_accuracy: 0.1412\n",
      "Epoch 78/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2734 - mae_all_class: 1.3888 - categorical_accuracy: 0.5467\n",
      "Epoch 00078: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2734 - mae_all_class: 1.3897 - categorical_accuracy: 0.5467 - val_loss: 4.7439 - val_mae_all_class: 4.3459 - val_categorical_accuracy: 0.1403\n",
      "Epoch 79/1000\n",
      "134272/134466 [============================>.] - ETA: 0s - loss: 1.2742 - mae_all_class: 1.3901 - categorical_accuracy: 0.5467\n",
      "Epoch 00079: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2743 - mae_all_class: 1.3961 - categorical_accuracy: 0.5467 - val_loss: 4.7511 - val_mae_all_class: 4.3366 - val_categorical_accuracy: 0.1418\n",
      "Epoch 80/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2780 - mae_all_class: 1.3937 - categorical_accuracy: 0.5470\n",
      "Epoch 00080: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2781 - mae_all_class: 1.3954 - categorical_accuracy: 0.5470 - val_loss: 4.7413 - val_mae_all_class: 4.3371 - val_categorical_accuracy: 0.1407\n",
      "Epoch 81/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2741 - mae_all_class: 1.3899 - categorical_accuracy: 0.5465\n",
      "Epoch 00081: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2742 - mae_all_class: 1.3972 - categorical_accuracy: 0.5465 - val_loss: 4.7544 - val_mae_all_class: 4.3366 - val_categorical_accuracy: 0.1416\n",
      "Epoch 82/1000\n",
      "134080/134466 [============================>.] - ETA: 0s - loss: 1.2706 - mae_all_class: 1.3837 - categorical_accuracy: 0.5477\n",
      "Epoch 00082: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2706 - mae_all_class: 1.3895 - categorical_accuracy: 0.5478 - val_loss: 4.7524 - val_mae_all_class: 4.3429 - val_categorical_accuracy: 0.1417\n",
      "Epoch 83/1000\n",
      "134080/134466 [============================>.] - ETA: 0s - loss: 1.2757 - mae_all_class: 1.3961 - categorical_accuracy: 0.5470\n",
      "Epoch 00083: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2757 - mae_all_class: 1.3959 - categorical_accuracy: 0.5470 - val_loss: 4.7507 - val_mae_all_class: 4.3443 - val_categorical_accuracy: 0.1426\n",
      "Epoch 84/1000\n",
      "134208/134466 [============================>.] - ETA: 0s - loss: 1.2759 - mae_all_class: 1.3936 - categorical_accuracy: 0.5464\n",
      "Epoch 00084: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2760 - mae_all_class: 1.3964 - categorical_accuracy: 0.5464 - val_loss: 4.7567 - val_mae_all_class: 4.3377 - val_categorical_accuracy: 0.1423\n",
      "Epoch 85/1000\n",
      "134208/134466 [============================>.] - ETA: 0s - loss: 1.2709 - mae_all_class: 1.3829 - categorical_accuracy: 0.5482\n",
      "Epoch 00085: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2713 - mae_all_class: 1.3848 - categorical_accuracy: 0.5480 - val_loss: 4.7530 - val_mae_all_class: 4.3367 - val_categorical_accuracy: 0.1412\n",
      "Epoch 86/1000\n",
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2768 - mae_all_class: 1.3941 - categorical_accuracy: 0.5452\n",
      "Epoch 00086: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2769 - mae_all_class: 1.3979 - categorical_accuracy: 0.5451 - val_loss: 4.7549 - val_mae_all_class: 4.3354 - val_categorical_accuracy: 0.1412\n",
      "Epoch 87/1000\n",
      "134208/134466 [============================>.] - ETA: 0s - loss: 1.2715 - mae_all_class: 1.3917 - categorical_accuracy: 0.5480\n",
      "Epoch 00087: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 106us/sample - loss: 1.2717 - mae_all_class: 1.3955 - categorical_accuracy: 0.5479 - val_loss: 4.7567 - val_mae_all_class: 4.3391 - val_categorical_accuracy: 0.1411\n",
      "Epoch 88/1000\n",
      "134208/134466 [============================>.] - ETA: 0s - loss: 1.2747 - mae_all_class: 1.3917 - categorical_accuracy: 0.5469\n",
      "Epoch 00088: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2748 - mae_all_class: 1.3969 - categorical_accuracy: 0.5469 - val_loss: 4.7510 - val_mae_all_class: 4.3416 - val_categorical_accuracy: 0.1414\n",
      "Epoch 89/1000\n",
      "134336/134466 [============================>.] - ETA: 0s - loss: 1.2742 - mae_all_class: 1.3911 - categorical_accuracy: 0.5471\n",
      "Epoch 00089: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2744 - mae_all_class: 1.3971 - categorical_accuracy: 0.5470 - val_loss: 4.7487 - val_mae_all_class: 4.3344 - val_categorical_accuracy: 0.1398\n",
      "Epoch 90/1000\n",
      "134016/134466 [============================>.] - ETA: 0s - loss: 1.2774 - mae_all_class: 1.3946 - categorical_accuracy: 0.5465\n",
      "Epoch 00090: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2773 - mae_all_class: 1.3984 - categorical_accuracy: 0.5466 - val_loss: 4.7474 - val_mae_all_class: 4.3350 - val_categorical_accuracy: 0.1423\n",
      "Epoch 91/1000\n",
      "134016/134466 [============================>.] - ETA: 0s - loss: 1.2754 - mae_all_class: 1.3975 - categorical_accuracy: 0.5466\n",
      "Epoch 00091: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2753 - mae_all_class: 1.4060 - categorical_accuracy: 0.5467 - val_loss: 4.7521 - val_mae_all_class: 4.3294 - val_categorical_accuracy: 0.1408\n",
      "Epoch 92/1000\n",
      "134016/134466 [============================>.] - ETA: 0s - loss: 1.2716 - mae_all_class: 1.3855 - categorical_accuracy: 0.5469\n",
      "Epoch 00092: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 107us/sample - loss: 1.2716 - mae_all_class: 1.3856 - categorical_accuracy: 0.5469 - val_loss: 4.7577 - val_mae_all_class: 4.3402 - val_categorical_accuracy: 0.1408\n",
      "Epoch 93/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134144/134466 [============================>.] - ETA: 0s - loss: 1.2737 - mae_all_class: 1.3984 - categorical_accuracy: 0.5473\n",
      "Epoch 00093: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2743 - mae_all_class: 1.4088 - categorical_accuracy: 0.5473 - val_loss: 4.7561 - val_mae_all_class: 4.3381 - val_categorical_accuracy: 0.1410\n",
      "Epoch 94/1000\n",
      "134400/134466 [============================>.] - ETA: 0s - loss: 1.2689 - mae_all_class: 1.3879 - categorical_accuracy: 0.5500\n",
      "Epoch 00094: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 15s 110us/sample - loss: 1.2690 - mae_all_class: 1.3975 - categorical_accuracy: 0.5500 - val_loss: 4.7435 - val_mae_all_class: 4.3378 - val_categorical_accuracy: 0.1407\n",
      "Epoch 95/1000\n",
      "134080/134466 [============================>.] - ETA: 0s - loss: 1.2708 - mae_all_class: 1.3850 - categorical_accuracy: 0.5500\n",
      "Epoch 00095: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 15s 111us/sample - loss: 1.2711 - mae_all_class: 1.3955 - categorical_accuracy: 0.5499 - val_loss: 4.7545 - val_mae_all_class: 4.3299 - val_categorical_accuracy: 0.1416\n",
      "Epoch 96/1000\n",
      "134336/134466 [============================>.] - ETA: 0s - loss: 1.2677 - mae_all_class: 1.3864 - categorical_accuracy: 0.5497\n",
      "Epoch 00096: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 15s 112us/sample - loss: 1.2677 - mae_all_class: 1.3937 - categorical_accuracy: 0.5496 - val_loss: 4.7578 - val_mae_all_class: 4.3458 - val_categorical_accuracy: 0.1414\n",
      "Epoch 97/1000\n",
      "134336/134466 [============================>.] - ETA: 0s - loss: 1.2750 - mae_all_class: 1.3824 - categorical_accuracy: 0.5478\n",
      "Epoch 00097: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 15s 112us/sample - loss: 1.2751 - mae_all_class: 1.3844 - categorical_accuracy: 0.5478 - val_loss: 4.7603 - val_mae_all_class: 4.3350 - val_categorical_accuracy: 0.1414\n",
      "Epoch 98/1000\n",
      "134464/134466 [============================>.] - ETA: 0s - loss: 1.2725 - mae_all_class: 1.3794 - categorical_accuracy: 0.5507\n",
      "Epoch 00098: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 104us/sample - loss: 1.2726 - mae_all_class: 1.3885 - categorical_accuracy: 0.5507 - val_loss: 4.7646 - val_mae_all_class: 4.3363 - val_categorical_accuracy: 0.1406\n",
      "Epoch 99/1000\n",
      "134272/134466 [============================>.] - ETA: 0s - loss: 1.2696 - mae_all_class: 1.3831 - categorical_accuracy: 0.5485\n",
      "Epoch 00099: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 105us/sample - loss: 1.2698 - mae_all_class: 1.3901 - categorical_accuracy: 0.5485 - val_loss: 4.7565 - val_mae_all_class: 4.3337 - val_categorical_accuracy: 0.1407\n",
      "Epoch 100/1000\n",
      "134080/134466 [============================>.] - ETA: 0s - loss: 1.2707 - mae_all_class: 1.3862 - categorical_accuracy: 0.5492\n",
      "Epoch 00100: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 104us/sample - loss: 1.2706 - mae_all_class: 1.3872 - categorical_accuracy: 0.5492 - val_loss: 4.7676 - val_mae_all_class: 4.3311 - val_categorical_accuracy: 0.1420\n",
      "Epoch 101/1000\n",
      "134016/134466 [============================>.] - ETA: 0s - loss: 1.2725 - mae_all_class: 1.3839 - categorical_accuracy: 0.5473\n",
      "Epoch 00101: val_categorical_accuracy did not improve from 0.14363\n",
      "134466/134466 [==============================] - 14s 104us/sample - loss: 1.2725 - mae_all_class: 1.3930 - categorical_accuracy: 0.5474 - val_loss: 4.7494 - val_mae_all_class: 4.3426 - val_categorical_accuracy: 0.1411\n",
      "Epoch 00101: early stopping\n",
      "37349/37349 [==============================] - 2s 46us/sample - loss: 4.7344 - mae_all_class: 4.4196 - categorical_accuracy: 0.1359\n",
      "[4.734354162360455, 4.4195614, 0.13593403]\n",
      "[[31 40 24 34 39]\n",
      " [11  7 12  4  6]\n",
      " [23 19 20 22 21]\n",
      " [41 45 44 42 43]\n",
      " [28 25 26 27 24]\n",
      " [18 19 20 22 21]\n",
      " [37 36 35 33 34]\n",
      " [47 41 48 46 33]\n",
      " [11  9 10 12 13]\n",
      " [ 6 20  7  4  5]]\n",
      "[28 13 24 50 25 19 30 30  7 22]\n"
     ]
    }
   ],
   "source": [
    "res = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
